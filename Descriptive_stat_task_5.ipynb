{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "\n",
    "# %%\n",
    "pdf_path = \"/Users/kishanterdal/Downloads/Descriptive_Task_05/2024SUStats.pdf\"\n",
    "\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    pdf_text = \"\"\n",
    "    for page in pdf.pages:\n",
    "        pdf_text += page.extract_text()\n",
    "\n",
    "pdf_text\n",
    "\n",
    "# %%\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=\"XX\",\n",
    ")\n",
    "\n",
    "### Replacing the api key with XX for security reasons\n",
    "\n",
    "question_block = \"\"\"\n",
    "    Please analyze the following Syracuse Women's Lacrosse 2024 season statistics and answer the following 7 high-impact questions. Be concise, but explain your reasoning when needed.\n",
    "\n",
    "1. How many total games did Syracuse play in the 2024 season?\n",
    "2. How many goals did Syracuse score in total during the season?\n",
    "3. What was Syracuse’s overall win-loss record in 2024?\n",
    "4. Did Syracuse score any goals in overtime during the 2024 season?\n",
    "5. What was the average number of goals scored by Syracuse per game?\n",
    "6. As a coach, if I wanted to win two more games this coming season, should I focus on offense or defense and If so, what is the one player I should work with to be a game changer and why?\n",
    "\n",
    "    Please format your response as:\n",
    "    Answer 1: ...\n",
    "    Answer 2: ...\n",
    "    Answer 3: ...\n",
    "    Answer 4: ...\n",
    "    Answer 5: ...\n",
    "    Answer 6: ...\n",
    "    \"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "        model=\"mistralai/mistral-7b-instruct:free\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a strategic sports analyst reviewing Syracuse Women's Lacrosse 2024 season statistics to identify areas of improvement that could help win more games.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Here is the full dataset:\\n\\n{pdf_text}\\n\\n{question_block}\"}\n",
    "        ],\n",
    "        temperature=0.5\n",
    "    )\n",
    "\n",
    "print(completion.choices[0].message.content)\n",
    "\n",
    "# %% [markdown]\n",
    "# In my initial experimentation with Mistral 7B Instruct, I observed that while the model **struggled with precise, fact-based questions** when applied to structured data (like sports statistics from a PDF).\n",
    "# \n",
    "# Specifically, when asked 5 straightforward questions about Syracuse Women's Lacrosse 2024 season:\n",
    "# \n",
    "# * Mistral **incorrectly calculated** the number of games played as **24 instead of 22**, despite the \"16-6\" record clearly indicating 22 games.\n",
    "# * It **hallucinated a total goal count** of **435**, by multiplying the per-game average by a wrong game count, instead of using the explicit total of **335 goals** from the \"Goals by Period\" table.\n",
    "# * It **invented a 16-8 win-loss record**, which contradicts the official \"16-6\" record stated in the data.\n",
    "# * Mistral consistently built logic on **fabricated data** (24 games, 435 goals, fake player)\n",
    "# \n",
    "# Due to this pattern of factual inaccuracies, I decided to evaluate **Google Gemma 3 12B Instruct**, which is open-weight and optimized for instruction-following and factual consistency.\n",
    "\n",
    "# %%\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=\"XX\"\n",
    ")\n",
    "\n",
    "### Replacing the api key with XX for security reasons\n",
    "\n",
    "question_block = \"\"\"\n",
    "Please analyze the following Syracuse Women's Lacrosse 2024 season statistics and answer the following 5 high-impact questions. Be concise, but explain your reasoning when needed.\n",
    "\n",
    "1. How many total games did Syracuse play in the 2024 season?\n",
    "2. How many goals did Syracuse score in total during the season?\n",
    "3. What was Syracuse’s overall win-loss record in 2024?\n",
    "4. Did Syracuse score any goals in overtime during the 2024 season?\n",
    "5. What was the average number of goals scored by Syracuse per game?\n",
    "6. As a coach, if I wanted to win two more games this coming season, should I focus on offense or defense and If so, what is the one player I should work with to be a game changer and why?\n",
    "\n",
    "Please format your response as:\n",
    "Answer 1: ...\n",
    "Answer 2: ...\n",
    "Answer 3: ...\n",
    "Answer 4: ...\n",
    "Answer 5: ...\n",
    "Answer 6: ...\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Call Gemma model through OpenRouter\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"google/gemma-3-12b-it:free\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a strategic sports analyst reviewing Syracuse Women's Lacrosse 2024 season statistics to identify areas of improvement that could help win more games.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Here is the full dataset:\\n\\n{pdf_text}\\n\\n{question_block}\"}\n",
    "    ],\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "# Print result\n",
    "print(completion.choices[0].message.content)\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# When tested with the **exact same dataset and questions**, **Gemma correctly answered all 5 questions**, including:\n",
    "# \n",
    "# * Correctly identifying the total games as **22**\n",
    "# * Accurately reporting **335 total goals** (as explicitly listed)\n",
    "# * Preserving the actual **16-6 win-loss record**\n",
    "# * Recognizing **zero goals scored in overtime**\n",
    "# * Using the given **15.23 average goals per game** directly instead of re-deriving it incorrectly\n",
    "# \n",
    "# This level of **grounded accuracy and reliability** makes Google Gemma a more suitable choice for structured analysis tasks, especially when precision matters.\n",
    "# \n",
    "\n",
    "# %% [markdown]\n",
    "# ###  Experimentation\n",
    "# \n",
    "# I will be experimenting with two open-source language models — **Mistral 7B Instruct** and **Google Gemma 3 12B Instruct** — to evaluate their performance on structured reasoning and factual analysis tasks. The evaluation will be conducted using **five distinct tests** designed to measure reliability, reasoning ability, and robustness in real-world scenarios.\n",
    "# \n",
    "# The five tests are:\n",
    "# \n",
    "# 1. **Repetition Consistency Test**\n",
    "#    To assess whether the model gives consistent answers to semantically equivalent questions.\n",
    "# \n",
    "# 2. **Multi-Hop Reasoning Test**\n",
    "#    To evaluate the model’s ability to combine multiple pieces of information and perform intermediate calculations.\n",
    "# \n",
    "# 3. **Prompt Robustness Test**\n",
    "#    To test how well the model performs with open-ended or ambiguous prompts.\n",
    "# \n",
    "# 4. **Math & Logic Problems**\n",
    "#    To check the model’s accuracy in basic arithmetic and logical deduction.\n",
    "# \n",
    "# 5. **Model Comparison Table**\n",
    "#    A side-by-side comparison of answers from both models across all test cases, with manual grading of correctness and quality.\n",
    "# \n",
    "# This structured evaluation will help determine which model is better suited for factual Q\\&A tasks involving structured data, such as sports analytics or performance summaries.\n",
    "\n",
    "# %%\n",
    "models = {\n",
    "    \"Mistral\": \"mistralai/mistral-7b-instruct:free\",\n",
    "    \"Gemma\": \"google/gemma-3-12b-it:free\"\n",
    "}\n",
    "\n",
    "questions = {\n",
    "    \"Repetition Consistency Test\": [\n",
    "        \"How many games did Syracuse play in 2024?\",\n",
    "        \"What was the total number of matches Syracuse played in the 2024 season?\"\n",
    "    ],\n",
    "    \"Multi-Hop Reasoning\": [\n",
    "        \"If Syracuse scored 335 goals in 22 games, what was their average goals per game?\",\n",
    "        \"If 65 of those 335 goals were from free positions, what percentage of Syracuse's goals were free-position goals?\"\n",
    "    ],\n",
    "    \"Prompt Robustness Test\": [\n",
    "        \"Tell me something insightful from Syracuse's 2024 lacrosse season stats.\",\n",
    "        \"What should a coach know about this team's performance?\"\n",
    "    ],\n",
    "    \"Math & Logic Problems\": [\n",
    "        \"If a player scores 2.5 goals in 10 games, how many total goals is that?\",\n",
    "        \"A team won 16 out of 22 games. What is their win percentage?\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# %%\n",
    "def ask_model(model_name, question):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant answering questions based on structured statistics or logic.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": question\n",
    "            }\n",
    "        ],\n",
    "        temperature=0.5\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "# %%\n",
    "results = []\n",
    "\n",
    "for test_name, qs in questions.items():\n",
    "    for q in qs:\n",
    "        mistral_answer = ask_model(models[\"Mistral\"], q)\n",
    "        gemma_answer = ask_model(models[\"Gemma\"], q)\n",
    "\n",
    "        results.append({\n",
    "            \"Test Case\": test_name,\n",
    "            \"Question\": q,\n",
    "            \"Mistral Answer\": mistral_answer,\n",
    "            \"Gemma Answer\": gemma_answer\n",
    "        })\n",
    "\n",
    "# %%\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"model_comparison_results.csv\", index=False)\n",
    "df\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Experiment Overview\n",
    "# \n",
    "# Two open-source large language models were evaluated:\n",
    "# \n",
    "# * **Mistral 7B Instruct** (`mistralai/mistral-7b-instruct:free`)\n",
    "# * **Google Gemma 3 12B Instruct** (`google/gemma-3-12b-it:free`)\n",
    "# \n",
    "# ### Evaluation Criteria:\n",
    "# \n",
    "# Models were tested on 5 categories:\n",
    "# \n",
    "# 1. **Repetition Consistency Test**\n",
    "# 2. **Multi-Hop Reasoning**\n",
    "# 3. **Prompt Robustness Test**\n",
    "# 4. **Math & Logic Problems**\n",
    "# 5. **Comparison Table (Ground Truth Matching)**\n",
    "# \n",
    "# ---\n",
    "# \n",
    "# ## 📊 Results Summary\n",
    "# \n",
    "# | Metric                               | Mistral 7B | Gemma 12B |\n",
    "# | ------------------------------------ | ---------- | --------- |\n",
    "# | ✅ Correct Answers (Objective Qs)     | 1          | 3         |\n",
    "# | ❌ Incorrect Answers                  | 5          | 3         |\n",
    "# | ⚖️ Subjective Questions (not graded) | 2          | 2         |\n",
    "# | 📈 Total Evaluated (objective only)  | 6          | 6         |\n",
    "# \n",
    "# ---\n",
    "# \n",
    "# ## 🔍 Detailed Question-by-Question Evaluation\n",
    "# \n",
    "# | Test Case              | Question                                                               | Ground Truth | Mistral Verdict | Gemma Verdict |\n",
    "# | ---------------------- | ---------------------------------------------------------------------- | ------------ | --------------- | ------------- |\n",
    "# | Repetition Consistency | How many games did Syracuse play in 2024?                              | 22           | Incorrect       | **Correct**   |\n",
    "# | Repetition Consistency | What was the total number of matches Syracuse played in 2024?          | 22           | Incorrect       | **Correct**   |\n",
    "# | Multi-Hop Reasoning    | If Syracuse scored 335 goals in 22 games, what was avg goals per game? | 15.23        | Incorrect       | **Correct**   |\n",
    "# | Multi-Hop Reasoning    | What % of goals were from free positions? (65 of 335)                  | 19.40%       | Incorrect       | Incorrect     |\n",
    "# | Prompt Robustness      | Tell me something insightful from the stats                            | —            | Subjective      | Subjective    |\n",
    "# | Prompt Robustness      | What should a coach know about performance?                            | —            | Subjective      | Subjective    |\n",
    "# | Math & Logic           | Player scores 2.5 goals in 10 games. Total goals?                      | 25.0         | **Correct**     | Incorrect     |\n",
    "# | Math & Logic           | Team wins 16 of 22 games. Win percentage?                              | 72.73%       | Incorrect       | Incorrect     |\n",
    "# \n",
    "# ---\n",
    "# \n",
    "# ## ✅ Key Observations\n",
    "# \n",
    "# * **Gemma** was consistently better at:\n",
    "# \n",
    "#   * Understanding structured data context (e.g., total games, goals)\n",
    "#   * Performing **multi-hop reasoning** and **unit math**\n",
    "# * **Mistral** struggled with:\n",
    "# \n",
    "#   * Basic arithmetic (e.g., percentage)\n",
    "#   * Grounded answers from context\n",
    "# * Both models handled **subjective prompts** reasonably, but those were excluded from scoring.\n",
    "# \n",
    "# ---\n",
    "# \n",
    "# ## 🏁 Final Verdict\n",
    "# \n",
    "# | Criteria               | Winner                                |\n",
    "# | ---------------------- | ------------------------------------- |\n",
    "# | Factual Accuracy       | ✅ **Gemma**                           |\n",
    "# | Multi-Step Reasoning   | ✅ **Gemma**                           |\n",
    "# | Basic Math Consistency | ❌ Neither (both failed % calculation) |\n",
    "# | Instruction Following  | ✅ **Gemma**                           |\n",
    "# | Overall                | ✅ **Gemma Wins**                      |\n",
    "# \n",
    "# ---\n",
    "# \n",
    "# \n",
    "# If the task involves **structured data interpretation**, **numerical reasoning**, or **sports analytics**, **Google Gemma 3 12B** is a more reliable choice than **Mistral 7B**.\n",
    "\n",
    "# %% [markdown]\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
